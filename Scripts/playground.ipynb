{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d967969",
   "metadata": {},
   "source": [
    "# Inférence de L'IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee215ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.8.0+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"torch:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd34225",
   "metadata": {},
   "source": [
    "#### Le modèle du multilayer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "137159b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=0.1)\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dropout(x)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "738f2593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.24.3\n",
      "Librosa version: 0.10.1\n",
      "✅ All libraries imported successfully!\n",
      "(13, 134)\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Run this cell ONLY after restarting the kernel!\n",
    "# Kernel -> Restart Kernel, then run this cell\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Librosa version: {librosa.__version__}\")\n",
    "\n",
    "PATH_FOLDER = \"../data/archive/DATASET_OF_VOWELS/\"\n",
    "\n",
    "def extract_features(file_path, folder_path=PATH_FOLDER, n_mfcc=13, n_fft=2048, hop_length=512):\n",
    "    y, sr = librosa.load(folder_path + file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    return mfccs\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "\n",
    "# Test with a sample file\n",
    "\n",
    "mffc = extract_features(\"he_1_ (70).wav\")\n",
    "\n",
    "print(mffc.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c1ecc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data\n",
    "\n",
    "list_vowels_training = ['a', 'e', 'i', 'o', 'u']\n",
    "list_speaker_training = np.arange(1, 4)\n",
    "list_numbers_training = np.arange(1, 37)\n",
    "\n",
    "# test_data\n",
    "\n",
    "list_vowels_testing = ['a', 'e', 'i', 'o', 'u']\n",
    "list_speaker_testing = np.arange(1, 4)\n",
    "list_numbers_testing = np.arange(45, 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412663f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4712aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Loss: 1.7048 accuracy: 20.00%\n",
      "Epoch [20/300], Loss: 1.7030 accuracy: 20.19%\n",
      "Epoch [30/300], Loss: 1.7030 accuracy: 20.19%\n",
      "Epoch [40/300], Loss: 1.7048 accuracy: 20.00%\n",
      "Epoch [50/300], Loss: 1.7012 accuracy: 20.37%\n",
      "Epoch [60/300], Loss: 1.7048 accuracy: 20.00%\n",
      "Epoch [70/300], Loss: 1.7029 accuracy: 20.19%\n",
      "Epoch [80/300], Loss: 1.6428 accuracy: 26.30%\n",
      "Epoch [90/300], Loss: 1.5369 accuracy: 36.85%\n",
      "Epoch [100/300], Loss: 1.5250 accuracy: 37.96%\n",
      "Epoch [110/300], Loss: 1.5410 accuracy: 36.48%\n",
      "Epoch [120/300], Loss: 1.5135 accuracy: 39.07%\n",
      "Epoch [130/300], Loss: 1.5139 accuracy: 39.07%\n",
      "Epoch [140/300], Loss: 1.5064 accuracy: 39.81%\n",
      "Epoch [150/300], Loss: 1.5178 accuracy: 38.70%\n",
      "Epoch [160/300], Loss: 1.5104 accuracy: 39.44%\n",
      "Epoch [170/300], Loss: 1.5062 accuracy: 39.81%\n",
      "Epoch [180/300], Loss: 1.5117 accuracy: 39.26%\n",
      "Epoch [190/300], Loss: 1.5102 accuracy: 39.44%\n",
      "Epoch [200/300], Loss: 1.5102 accuracy: 39.44%\n",
      "Epoch [210/300], Loss: 1.5065 accuracy: 39.81%\n",
      "Epoch [220/300], Loss: 1.5080 accuracy: 39.63%\n",
      "Epoch [230/300], Loss: 1.5078 accuracy: 39.63%\n",
      "Epoch [240/300], Loss: 1.5080 accuracy: 39.63%\n",
      "Epoch [250/300], Loss: 1.5083 accuracy: 39.63%\n",
      "Epoch [260/300], Loss: 1.5119 accuracy: 39.26%\n",
      "Epoch [270/300], Loss: 1.5138 accuracy: 39.07%\n",
      "Epoch [280/300], Loss: 1.5120 accuracy: 39.26%\n",
      "Epoch [290/300], Loss: 1.5119 accuracy: 39.26%\n",
      "Epoch [300/300], Loss: 1.5138 accuracy: 39.07%\n",
      "✅ Entraînement terminé !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for vowel in list_vowels_training:\n",
    "    for speaker in list_speaker_training:\n",
    "        for number in list_numbers_training:\n",
    "            filename = f\"h{vowel}_{speaker}_ ({number}).wav\"\n",
    "            mfcc = extract_features(filename)\n",
    "            feature_vector = np.mean(mfcc, axis=1)\n",
    "            X_train.append(feature_vector)\n",
    "            y_train.append(list_vowels_training.index(vowel))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "11f316e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Loss: 1.6786 accuracy: 22.41%\n",
      "Epoch [20/300], Loss: 1.6705 accuracy: 22.78%\n",
      "Epoch [30/300], Loss: 1.5242 accuracy: 37.78%\n",
      "Epoch [40/300], Loss: 1.4988 accuracy: 40.37%\n",
      "Epoch [50/300], Loss: 1.4780 accuracy: 42.04%\n",
      "Epoch [60/300], Loss: 1.4443 accuracy: 45.56%\n",
      "Epoch [70/300], Loss: 1.4344 accuracy: 47.41%\n",
      "Epoch [80/300], Loss: 1.4252 accuracy: 47.59%\n",
      "Epoch [90/300], Loss: 1.3967 accuracy: 51.11%\n",
      "Epoch [100/300], Loss: 1.3988 accuracy: 50.00%\n",
      "Epoch [110/300], Loss: 1.3554 accuracy: 55.37%\n",
      "Epoch [120/300], Loss: 1.2988 accuracy: 60.74%\n",
      "Epoch [130/300], Loss: 1.2810 accuracy: 62.04%\n",
      "Epoch [140/300], Loss: 1.1549 accuracy: 74.63%\n",
      "Epoch [150/300], Loss: 1.1141 accuracy: 79.44%\n",
      "Epoch [160/300], Loss: 1.0960 accuracy: 81.48%\n",
      "Epoch [170/300], Loss: 1.0935 accuracy: 80.56%\n",
      "Epoch [180/300], Loss: 1.0937 accuracy: 81.67%\n",
      "Epoch [190/300], Loss: 1.0781 accuracy: 83.15%\n",
      "Epoch [200/300], Loss: 1.0841 accuracy: 82.59%\n",
      "Epoch [210/300], Loss: 1.0788 accuracy: 83.89%\n",
      "Epoch [220/300], Loss: 1.0740 accuracy: 83.52%\n",
      "Epoch [230/300], Loss: 1.0824 accuracy: 82.41%\n",
      "Epoch [240/300], Loss: 1.0863 accuracy: 81.67%\n",
      "Epoch [250/300], Loss: 1.0968 accuracy: 81.67%\n",
      "Epoch [260/300], Loss: 1.0686 accuracy: 84.07%\n",
      "Epoch [270/300], Loss: 1.0681 accuracy: 84.26%\n",
      "Epoch [280/300], Loss: 1.0385 accuracy: 87.22%\n",
      "Epoch [290/300], Loss: 1.0497 accuracy: 85.56%\n",
      "Epoch [300/300], Loss: 1.0662 accuracy: 84.07%\n",
      "✅ Entraînement terminé !\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = len(list_vowels_training)\n",
    "mlp_model = MLP(input_size, hidden_size, output_size)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=0.0005)\n",
    "\n",
    "num_epochs = 300\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = mlp_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f} accuracy: {100 * (outputs.argmax(dim=1) == y_train_tensor).float().mean().item():.2f}%\")\n",
    "\n",
    "print(\"✅ Entraînement terminé !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfee37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_252729/1657431995.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal = librosa.load(data, sr=None)[0]\n",
      "/home/lienard/anaconda3/envs/audio_env/lib/python3.11/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/archive/DATASET_OF_VOWELS/he_a_1_ (1).wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLibsndfileError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/audio_env/lib/python3.11/site-packages/librosa/core/audio.py:175\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     y, sr_native = \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m sf.SoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    178\u001b[39m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/audio_env/lib/python3.11/site-packages/librosa/core/audio.py:208\u001b[39m, in \u001b[36m__soundfile_load\u001b[39m\u001b[34m(path, offset, duration, dtype)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     context = \u001b[43msf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/audio_env/lib/python3.11/site-packages/soundfile.py:690\u001b[39m, in \u001b[36mSoundFile.__init__\u001b[39m\u001b[34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[39m\n\u001b[32m    688\u001b[39m \u001b[38;5;28mself\u001b[39m._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[32m    689\u001b[39m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m \u001b[38;5;28mself\u001b[39m._file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode).issuperset(\u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.seekable():\n\u001b[32m    692\u001b[39m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/audio_env/lib/python3.11/site-packages/soundfile.py:1265\u001b[39m, in \u001b[36mSoundFile._open\u001b[39m\u001b[34m(self, file, mode_int, closefd)\u001b[39m\n\u001b[32m   1264\u001b[39m     err = _snd.sf_error(file_ptr)\n\u001b[32m-> \u001b[39m\u001b[32m1265\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix=\u001b[33m\"\u001b[39m\u001b[33mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m.name))\n\u001b[32m   1266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode_int == _snd.SFM_WRITE:\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[31mLibsndfileError\u001b[39m: Error opening '../data/archive/DATASET_OF_VOWELS/he_a_1_ (1).wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m### check \u001b[39;00m\n\u001b[32m      4\u001b[39m data = PATH_FOLDER + \u001b[33m\"\u001b[39m\u001b[33mhe_a_1_ (1).wav\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m signal = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(signal.shape)\n\u001b[32m      9\u001b[39m plt.plot(signal)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/audio_env/lib/python3.11/site-packages/librosa/core/audio.py:183\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib.PurePath)):\n\u001b[32m    180\u001b[39m     warnings.warn(\n\u001b[32m    181\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[33m\"\u001b[39m, stacklevel=\u001b[32m2\u001b[39m\n\u001b[32m    182\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     y, sr_native = \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/audio_env/lib/python3.11/site-packages/decorator.py:235\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m    234\u001b[39m     args, kw = fix(args, kw, sig)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/audio_env/lib/python3.11/site-packages/librosa/util/decorators.py:59\u001b[39m, in \u001b[36mdeprecated.<locals>.__wrapper\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m warnings.warn(\n\u001b[32m     52\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m     stacklevel=\u001b[32m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[32m     58\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/audio_env/lib/python3.11/site-packages/librosa/core/audio.py:239\u001b[39m, in \u001b[36m__audioread_load\u001b[39m\u001b[34m(path, offset, duration, dtype)\u001b[39m\n\u001b[32m    236\u001b[39m     reader = path\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    238\u001b[39m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     reader = \u001b[43maudioread\u001b[49m\u001b[43m.\u001b[49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[32m    242\u001b[39m     sr_native = input_file.samplerate\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/audio_env/lib/python3.11/site-packages/audioread/__init__.py:127\u001b[39m, in \u001b[36maudio_open\u001b[39m\u001b[34m(path, backends)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/audio_env/lib/python3.11/site-packages/audioread/rawread.py:59\u001b[39m, in \u001b[36mRawAudioFile.__init__\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28mself\u001b[39m._fh = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m         \u001b[38;5;28mself\u001b[39m._file = aifc.open(\u001b[38;5;28mself\u001b[39m._fh)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/archive/DATASET_OF_VOWELS/he_a_1_ (1).wav'"
     ]
    }
   ],
   "source": [
    "### check \n",
    "\n",
    "\n",
    "data = PATH_FOLDER + \"he_1_ (1).wav\"\n",
    "\n",
    "signal = librosa.load(data, sr=None)[0]\n",
    "\n",
    "print(signal.shape)\n",
    "plt.plot(signal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
